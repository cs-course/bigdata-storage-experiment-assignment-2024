# 实验名称
    观测分析性能
# 实验环境
    Ubuntu 22.04
    Python 3.10.2 + swiftclient
# 实验记录
## 实验选题
    请求并发数如何同时影响延迟分布和吞吐率
## 实验过程
    1. 创建测试文件 test.txt(4MB全空)
    2. 创建测试容器 TestBucket
    3. 依次启动 4,8,16,32,64,128,256个线程，每个线程执行put操作或get操作,同一线程一次测试只会执行一次操作，记录耗时
    4. 计算平均延迟和吞吐量
    5. 画图分析

并发数对延迟的影响如下图所示<br>
![Put-Latency](./figure/put%20lantency.png)
![Get-Latency](./figure/Get%20lantency.png)


并发数对吞吐量的影响如下图所示<br>
![Put-Throughput](./figure/Put%20Throughput.png)
![Get-Throughput](./figure/Get%20throughput.png)

分析:  
1. 无论是读操作还是写操作，普遍来看延迟都随着并发数线性增加(仅在并发数由4到8时延迟略微减小)
2. 在本测试，写操作的吞吐量随并发数增长，在并发数小于等于16时，吞吐量增长显著;在16-64区间，增速大幅放缓;在高于64-128时增速略有提升，随后放缓
3. 读操作吞吐量在64并发数时达到最大随后降低;在并发数小于16时增长最为显著

结论:
1. 提高并发数会增大操作的延迟
2. 在并发数较小时提高并发数可以获得极大的吞吐量提升，在并发数高于64之后再提高并发数，吞吐量提升不大甚至会降低
   
如何在高并发场景下提升服务质量:  
1. 优化并发访问:对代码和配置进行优化，以减少锁竞争、减少资源争用等。
2. 负载均衡: 使用负载均衡器将请求分发到多个服务器上，以确保单个服务器不会过度负载。
3. 缓存: 利用缓存来减少频繁访问,减轻存储系统的压力并提高响应速度。
4. 限流和排队: 实施限流和排队机制，以控制并发请求的数量。
5. 异步处理: 将处理任务异步化，以减少每个请求的处理时间。
6. 监控和调优: 持续监控系统的性能和负载情况，并根据需要进行调优和优化。


    

# 实验小结
参考[Swift-API-Document](https://docs.openstack.org/python-swiftclient/latest/swiftclient.html)执行增删查改操作  
参考[Python-Matplotlib](https://matplotlib.org/stable/tutorials/index)学习绘图